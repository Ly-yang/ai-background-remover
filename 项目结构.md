# AI Background Remover - 生产级智能抠图工具

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-brightgreen.svg)
![React](https://img.shields.io/badge/react-18.0+-blue.svg)
![FastAPI](https://img.shields.io/badge/fastapi-0.100+-green.svg)

一个基于最新AI技术的生产级背景移除工具，支持多种深度学习模型，提供高质量的抠图效果。

## ✨ 特性

- 🎯 **多模型支持**: 集成RMBG-2.0、U²-Net、BiRefNet、SAM等先进模型
- ⚡ **高性能处理**: GPU加速，批量处理支持
- 🎨 **现代化UI**: 响应式设计，流畅的用户体验
- 🔧 **灵活配置**: 支持多种处理模式和输出格式
- 📊 **实时监控**: 处理进度追踪和性能监控
- 🚀 **生产就绪**: Docker部署，自动扩缩容
- 🔒 **安全可靠**: JWT认证，API限流保护

## 🏗️ 项目结构

```
ai-background-remover/
├── frontend/                   # React前端应用
│   ├── public/
│   ├── src/
│   │   ├── components/        # 可复用组件
│   │   ├── pages/            # 页面组件
│   │   ├── hooks/            # 自定义Hooks
│   │   ├── utils/            # 工具函数
│   │   ├── store/            # 状态管理
│   │   └── styles/           # 样式文件
│   ├── package.json
│   └── vite.config.js
├── backend/                    # FastAPI后端服务
│   ├── app/
│   │   ├── api/              # API路由
│   │   │   ├── v1/
│   │   │   │   ├── auth.py
│   │   │   │   ├── images.py
│   │   │   │   └── models.py
│   │   │   └── deps.py
│   │   ├── core/             # 核心配置
│   │   │   ├── config.py
│   │   │   ├── security.py
│   │   │   └── database.py
│   │   ├── models/           # 数据模型
│   │   │   ├── user.py
│   │   │   ├── image.py
│   │   │   └── task.py
│   │   ├── services/         # 业务逻辑
│   │   │   ├── ai_processor.py
│   │   │   ├── image_service.py
│   │   │   └── queue_service.py
│   │   ├── utils/            # 工具函数
│   │   │   ├── image_utils.py
│   │   │   └── validators.py
│   │   └── main.py
│   ├── requirements.txt
│   └── Dockerfile
├── ai-models/                  # AI模型服务
│   ├── models/
│   │   ├── rmbg/             # RMBG模型
│   │   ├── u2net/            # U²-Net模型
│   │   ├── birefnet/         # BiRefNet模型
│   │   ├── sam/              # SAM模型
│   │   └── isnet/            # ISNet模型
│   ├── processors/
│   │   ├── base_processor.py
│   │   ├── rmbg_processor.py
│   │   ├── u2net_processor.py
│   │   ├── birefnet_processor.py
│   │   ├── sam_processor.py
│   │   └── isnet_processor.py
│   ├── utils/
│   │   ├── model_loader.py
│   │   ├── image_preprocessing.py
│   │   └── postprocessing.py
│   ├── requirements.txt
│   └── Dockerfile
├── database/                   # 数据库相关
│   ├── migrations/
│   ├── init.sql
│   └── docker-compose.yml
├── infrastructure/             # 基础设施配置
│   ├── kubernetes/
│   │   ├── frontend/
│   │   ├── backend/
│   │   ├── ai-models/
│   │   └── monitoring/
│   ├── terraform/
│   │   ├── aws/
│   │   ├── gcp/
│   │   └── azure/
│   └── docker/
│       └── docker-compose.prod.yml
├── monitoring/                 # 监控配置
│   ├── prometheus/
│   ├── grafana/
│   └── alerts/
├── tests/                      # 测试文件
│   ├── frontend/
│   ├── backend/
│   └── ai-models/
├── docs/                       # 文档
│   ├── api/
│   ├── deployment/
│   └── development/
├── scripts/                    # 部署脚本
│   ├── setup.sh
│   ├── deploy.sh
│   └── test.sh
├── .github/                    # GitHub Actions
│   └── workflows/
│       ├── ci.yml
│       ├── cd.yml
│       └── security.yml
├── docker-compose.yml
├── README.md
├── LICENSE
└── .gitignore
```

## 🚀 快速开始

### 环境要求

- Python 3.8+
- Node.js 16+
- Docker & Docker Compose
- CUDA 11.8+ (GPU版本)

### 安装步骤

1. **克隆项目**
```bash
git clone https://github.com/yourusername/ai-background-remover.git
cd ai-background-remover
```

2. **设置环境变量**
```bash
cp .env.example .env
# 编辑 .env 文件，配置必要的环境变量
```

3. **启动服务**
```bash
# 开发环境
docker-compose up -d

# 生产环境
docker-compose -f infrastructure/docker/docker-compose.prod.yml up -d
```

4. **访问应用**
- 前端: http://localhost:3000
- 后端API: http://localhost:8000
- API文档: http://localhost:8000/docs

## 🧠 AI模型支持

### RMBG-2.0 (推荐)
- **特点**: 最新的背景移除模型，效果最佳
- **适用**: 人物、物体、动物等通用场景
- **精度**: ★★★★★
- **速度**: ★★★★☆

### U²-Net
- **特点**: 经典的语义分割网络
- **适用**: 通用背景移除
- **精度**: ★★★★☆
- **速度**: ★★★★★

### BiRefNet
- **特点**: 高精度边缘处理
- **适用**: 需要精细边缘的场景
- **精度**: ★★★★★
- **速度**: ★★★☆☆

### SAM (Segment Anything)
- **特点**: Meta开源的通用分割模型
- **适用**: 复杂场景分割
- **精度**: ★★★★★
- **速度**: ★★☆☆☆

### ISNet-Anime
- **特点**: 专门针对动漫图像优化
- **适用**: 动漫、插画等二次元图像
- **精度**: ★★★★★
- **速度**: ★★★★☆

## 📊 API文档

### 上传图片
```http
POST /api/v1/images/upload
Content-Type: multipart/form-data

{
  "file": "image file",
  "model": "rmbg-2.0",
  "mode": "auto",
  "edge_optimization": "smooth",
  "output_format": "png"
}
```

### 获取处理结果
```http
GET /api/v1/images/{task_id}/result
Authorization: Bearer {token}
```

### 批量处理
```http
POST /api/v1/images/batch
Content-Type: application/json

{
  "images": ["image_id_1", "image_id_2"],
  "settings": {
    "model": "rmbg-2.0",
    "mode": "auto"
  }
}
```

## 🔧 配置选项

### 模型配置
```yaml
# ai-models/config.yml
models:
  rmbg:
    model_path: "./models/rmbg/model.pth"
    device: "cuda"
    batch_size: 4
    input_size: [1024, 1024]
  
  u2net:
    model_path: "./models/u2net/u2net.pth"
    device: "cuda"
    batch_size: 8
    input_size: [320, 320]
```

### 服务配置
```python
# backend/app/core/config.py
class Settings:
    PROJECT_NAME: str = "AI Background Remover"
    VERSION: str = "1.0.0"
    API_V1_STR: str = "/api/v1"
    
    # 数据库配置
    DATABASE_URL: str = "postgresql://user:pass@localhost/db"
    
    # Redis配置
    REDIS_URL: str = "redis://localhost:6379"
    
    # 文件存储
    UPLOAD_DIR: str = "./uploads"
    MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB
    
    # AI模型配置
    MODEL_SERVER_URL: str = "http://localhost:8001"
    DEFAULT_MODEL: str = "rmbg-2.0"
```

## 📈 性能优化

### GPU加速
```python
# ai-models/processors/base_processor.py
import torch

class BaseProcessor:
    def __init__(self, model_path: str, device: str = "cuda"):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.model = self.load_model(model_path).to(self.device)
        
        # 启用TensorRT优化 (可选)
        if torch.cuda.is_available():
            self.model = torch.jit.script(self.model)
```

### 批量处理
```python
# ai-models/processors/batch_processor.py
async def process_batch(images: List[PIL.Image], model: str) -> List[PIL.Image]:
    processor = get_processor(model)
    
    # 批量预处理
    batch_tensors = []
    for img in images:
        tensor = processor.preprocess(img)
        batch_tensors.append(tensor)
    
    batch_input = torch.stack(batch_tensors)
    
    # 批量推理
    with torch.no_grad():
        batch_output = processor.model(batch_input)
    
    # 批量后处理
    results = []
    for i, output in enumerate(batch_output):
        result = processor.postprocess(output, images[i].size)
        results.append(result)
    
    return results
```

### 缓存策略
```python
# backend/app/services/image_service.py
from redis import Redis
import hashlib

class ImageService:
    def __init__(self):
        self.redis = Redis.from_url(settings.REDIS_URL)
    
    async def process_image(self, image: bytes, settings: dict) -> bytes:
        # 生成缓存键
        cache_key = self.generate_cache_key(image, settings)
        
        # 检查缓存
        cached_result = self.redis.get(cache_key)
        if cached_result:
            return cached_result
        
        # 处理图片
        result = await self.ai_processor.process(image, settings)
        
        # 缓存结果 (24小时)
        self.redis.setex(cache_key, 86400, result)
        
        return result
```

## 🐳 Docker部署

### 开发环境
```yaml
# docker-compose.yml
version: '3.8'

services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/airemover
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    volumes:
      - ./uploads:/app/uploads

  ai-models:
    build: ./ai-models
    ports:
      - "8001:8001"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./models:/app/models

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=airemover
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

### 生产环境
```yaml
# infrastructure/docker/docker-compose.prod.yml
version: '3.8'

services:
  frontend:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./frontend/dist:/usr/share/nginx/html
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl

  backend:
    build: ./backend
    environment:
      - ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 2G
          cpus: "1.0"

  ai-models:
    build: ./ai-models
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ☸️ Kubernetes部署

### Backend服务
```yaml
# infrastructure/kubernetes/backend/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-remover-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-remover-backend
  template:
    metadata:
      labels:
        app: ai-remover-backend
    spec:
      containers:
      - name: backend
        image: ai-remover/backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
---
apiVersion: v1
kind: Service
metadata:
  name: ai-remover-backend-service
spec:
  selector:
    app: ai-remover-backend
  ports:
  - port: 8000
    targetPort: 8000
  type: LoadBalancer
```

### AI Models服务
```yaml
# infrastructure/kubernetes/ai-models/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-remover-models
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-remover-models
  template:
    metadata:
      labels:
        app: ai-remover-models
    spec:
      containers:
      - name: ai-models
        image: ai-remover/ai-models:latest
        ports:
        - containerPort: 8001
        resources:
          requests:
            memory: "4Gi"
            cpu: "1000m"
            nvidia.com/gpu: 1
          limits:
            memory: "8Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: model-storage
          mountPath: /app/models
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc
```

## 📊 监控和日志

### Prometheus配置
```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'ai-remover-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: /metrics

  - job_name: 'ai-remover-models'
    static_configs:
      - targets: ['ai-models:8001']
    metrics_path: /metrics
```

### Grafana仪表板
```json
{
  "dashboard": {
    "title": "AI Background Remover Metrics",
    "panels": [
      {
        "title": "处理请求数",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "GPU使用率",
        "type": "graph",
        "targets": [
          {
            "expr": "nvidia_gpu_utilization_gpu",
            "legendFormat": "GPU {{gpu}}"
          }
        ]
      }
    ]
  }
}
```

## 🧪 测试

### 单元测试
```python
# tests/backend/test_image_service.py
import pytest
from app.services.image_service import ImageService

@pytest.fixture
def image_service():
    return ImageService()

@pytest.mark.asyncio
async def test_process_image(image_service):
    # 测试图片处理
    with open("test_image.jpg", "rb") as f:
        image_data = f.read()
    
    result = await image_service.process_image(
        image_data, 
        {"model": "rmbg-2.0", "mode": "auto"}
    )
    
    assert result is not None
    assert len(result) > 0
```

### 集成测试
```python
# tests/integration/test_api.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_upload_image():
    with open("test_image.jpg", "rb") as f:
        response = client.post(
            "/api/v1/images/upload",
            files={"file": ("test.jpg", f, "image/jpeg")},
            data={"model": "rmbg-2.0"}
        )
    
    assert response.status_code == 200
    assert "task_id" in response.json()
```

## 🚀 部署指南

### AWS部署
```bash
# 使用Terraform部署到AWS
cd infrastructure/terraform/aws
terraform init
terraform plan
terraform apply
```

### GCP部署
```bash
# 使用Google Cloud Run部署
gcloud run deploy ai-remover-backend \
  --image gcr.io/PROJECT_ID/ai-remover-backend \
  --region us-central1 \
  --allow-unauthenticated
```

### Azure部署
```bash
# 使用Azure Container Instances
az container create \
  --resource-group ai-remover-rg \
  --name ai-remover-backend \
  --image ai-remover/backend:latest \
  --ports 8000
```

## 📝 API限流和安全

### JWT认证
```python
# backend/app/core/security.py
from jose import JWTError, jwt
from passlib.context import CryptContext

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt
```

### API限流
```python
# backend/app/api/deps.py
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post("/upload")
@limiter.limit("10/minute")
async def upload_image(request: Request, file: UploadFile):
    # 处理上传逻辑
    pass
```

## 🤝 贡献指南

1. Fork项目
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 打开Pull Request

## 📄 许可证

本项目采用MIT许可证 - 查看 [LICENSE](LICENSE) 文件了解详情

## 🙏 致谢

- [RMBG](https://github.com/zhengpeng7/BiRefNet) - 背景移除模型
- [U²-Net](https://github.com/xuebinqin/U-2-Net) - 语义分割网络
- [SAM](https://github.com/facebookresearch/segment-anything) - Meta分割模型
- [FastAPI](https://fastapi.tiangolo.com/) - 现代Python Web框架
- [React](https://reactjs.org/) - 用户界面库

---

⭐ 如果这个项目对你有帮助，请给我们一个星星！
